{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom class dictionary\n",
    "class_dict = {0: 'unclassified'}  # Class IDs start from 0 in Detectron2\n",
    "\n",
    "# Load config from a config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/retinanet_R_101_FPN_3x.yaml'))\n",
    "cfg.MODEL.WEIGHTS = '/home/gpu1/Documents/Projects/Mandar/train-object-detector-detectron2/output/model_final.pth'\n",
    "cfg.MODEL.DEVICE = 'cuda'\n",
    "\n",
    "# Create predictor instance\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "input_directory = input('Input directory: ')\n",
    "output_directory = input('Output directory: ')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of image files\n",
    "image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "# Create a tqdm progress bar\n",
    "with tqdm(total=len(image_files), unit='image') as pbar:\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_directory, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Perform prediction\n",
    "        outputs = predictor(image)\n",
    "        threshold = 0.5\n",
    "\n",
    "        # Check if there are any detections with scores above the threshold\n",
    "        has_detections = any(score > threshold for score in outputs[\"instances\"].scores)\n",
    "\n",
    "        if has_detections:\n",
    "            # Create an XML annotation for the image with detections\n",
    "            annotation = etree.Element(\"annotation\")\n",
    "            folder = etree.SubElement(annotation, \"folder\")\n",
    "            folder.text = os.path.basename(input_directory)\n",
    "            filename = etree.SubElement(annotation, \"filename\")\n",
    "            filename.text = image_file\n",
    "            source = etree.SubElement(annotation, \"source\")\n",
    "            database = etree.SubElement(source, \"database\")\n",
    "            database.text = \"Unknown\"\n",
    "            annotation_element = etree.SubElement(source, \"annotation\")\n",
    "            annotation_element.text = \"Unknown\"\n",
    "            image_source = etree.SubElement(source, \"image\")\n",
    "            image_source.text = \"Unknown\"\n",
    "            size = etree.SubElement(annotation, \"size\")\n",
    "            width = etree.SubElement(size, \"width\")\n",
    "            height = etree.SubElement(size, \"height\")\n",
    "            height.text = str(image.shape[0])\n",
    "            width.text = str(image.shape[1])\n",
    "            segmented = etree.SubElement(annotation, \"segmented\")\n",
    "            segmented.text = \"0\"\n",
    "\n",
    "            # Loop through the detected objects and add them to the XML\n",
    "            for j, bbox in enumerate(outputs[\"instances\"].pred_boxes.tensor):\n",
    "                x1, y1, x2, y2 = [int(i) for i in bbox.tolist()]\n",
    "                score = outputs[\"instances\"].scores[j]\n",
    "                pred = outputs[\"instances\"].pred_classes[j]\n",
    "\n",
    "                if score > threshold:\n",
    "                    object_elem = etree.SubElement(annotation, \"object\")\n",
    "                    name = etree.SubElement(object_elem, \"name\")\n",
    "                    name.text = class_dict[int(pred)]\n",
    "                    truncated = etree.SubElement(object_elem, \"truncated\")\n",
    "                    truncated.text = \"0\"\n",
    "                    occluded = etree.SubElement(object_elem, \"occluded\")\n",
    "                    occluded.text = \"0\"\n",
    "                    difficult = etree.SubElement(object_elem, \"difficult\")\n",
    "                    difficult.text = \"0\"\n",
    "                    bndbox = etree.SubElement(object_elem, \"bndbox\")\n",
    "                    xmin = etree.SubElement(bndbox, \"xmin\")\n",
    "                    ymin = etree.SubElement(bndbox, \"ymin\")\n",
    "                    xmax = etree.SubElement(bndbox, \"xmax\")\n",
    "                    ymax = etree.SubElement(bndbox, \"ymax\")\n",
    "                    xmin.text = str(x1)\n",
    "                    ymin.text = str(y1)\n",
    "                    xmax.text = str(x2)\n",
    "                    ymax.text = str(y2)\n",
    "\n",
    "            # Save the annotation as an XML file\n",
    "            annotation_file = os.path.splitext(image_file)[0] + '.xml'\n",
    "            annotation_path = os.path.join(output_directory, annotation_file)\n",
    "            with open(annotation_path, 'wb') as xml_file:\n",
    "                xml_file.write(etree.tostring(annotation, pretty_print=True))\n",
    "\n",
    "            # Copy the image to the output directory\n",
    "            output_image_path = os.path.join(output_directory, image_file)\n",
    "            cv2.imwrite(output_image_path, image)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
